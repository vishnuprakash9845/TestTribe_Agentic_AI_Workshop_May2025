# --------------------------
# Provider switch
# --------------------------
# Options: ollama | openai | anthropic | google
PROVIDER=ollama

# Model to use
# Examples:
# - Ollama: mistral:latest | codegemma:latest | gpt-oss:20b
# - OpenAI: gpt-5-nano | gpt-4o-mini
# - Anthropic: claude-3-sonnet
# - Google: gemini-1.5-pro
MODEL=mistral:latest

# --------------------------
# Provider credentials / host
# --------------------------
# Ollama runs locally on port 11434
OLLAMA_HOST=http://localhost:11434

# OpenAI API Key (only required if PROVIDER=openai)
OPENAI_API_KEY=

# Anthropic API Key (only required if PROVIDER=anthropic)
ANTHROPIC_API_KEY=

# Google Gemini API Key (only required if PROVIDER=google)
GOOGLE_API_KEY=

# --------------------------
# App settings
# --------------------------
LOG_LEVEL=INFO
OUTPUT_DIR=outputs

LLM_LOG=1
LLM_DEBUG=0


# --------------------------
# TestRail integration settings
# --------------------------
TESTRAIL_BASE=http://localhost:4002
TESTRAIL_PROJECT_ID=1
TESTRAIL_SECTION_ID=1

# --------------------------
# JIRA integration settings
# --------------------------
JIRA_BASE=http://localhost:4001
JIRA_PROJECT_KEY=QA
JIRA_BEARER=demo-token

# --------------------------
# SLACK integration settings
# --------------------------
SLACK_BASE=http://localhost:4003
SLACK_DEFAULT_CHANNEL=qa-reports
SLACK_BEARER=demo-token